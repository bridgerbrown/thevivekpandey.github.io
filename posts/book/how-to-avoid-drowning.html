<html>
<head>
  <title> How to avoid drowning</title>
  <link rel="stylesheet" type="text/css" href="../style.css"/>
</head>
<body>
<h2>How to avoid drowning</h2>
<p>
At IIT Kanpur, I had a friend, called Abhishek Tiwari. We used to call him "Darjan", because his 
IIT JEE rank was 12. Abhishek once asked a bunch of us a question: "If you are drowning, what is 
the prerequisite for you to be saved?". Some answered that you should know swimming, others answered 
that some of your friends should know swimming. Some replied that you should shout. The correct 
answer was: "You should be aware that you are drowning."
</p>

<p>
That is true of computer systems, as it is true for humans. You canâ€™t resolve the problems in systems, 
unless you are aware of the problems. And for you to be aware of the problems, you need to monitor 
what is happening.
</p>

<p>
You may have a great mind, but to survive, you need to see and hear and feel what is happening around
you. An average mind with great curiosity is better a great mind with a mild curiosity about what 
is happening around you.
</p>

<p>
I have found that too often, engineers are either too confident that their systems will obviously
work correctly for all times to come, or have an ostrich attitude: they just don't dare to 
find if their systems are working correctly, lest they accidentally open a can of worms.
</p>

<p>
There was once telephony company. They built software which would route calls made to a customer 
support number to one of several agents. The agent would have the calling customer's details available 
on their laptop as they talked to the customer. Once, because of some problem, for a particular
client, the software stopped working. No customers were getting routed to any agents.
</p>

<p>
The client company decided not to report this to the telephony company. They were testing how
soon will the problem be detected. Well, the problem was never detected, and the client company
terminated the contract after one month.
</p>

<p>
This is the normal state of affairs if one does not actively monitor one's systems.
</p>

<p>
There is no silver bullet for monitoring. The guiding principle is: any piece of software should
produce some easily comprehensible summary output to prove that it is working correctly. This summary
output would mostly be some numbers, which are easy to chart or detect anomalies in, but it could
also be in some other format: tables or pictures or flamegraphs, whatever is easier to comprehend.
</p>

<h3>Monitoring as first class activity</h3>

<p>
A "First class activity" is an activity that you take conscious effort to do, not as a side
effect of some other activity, but as an activity in itself.
</p>

<p>
Writing code clearly is a first class activity. Testing too gets a lot of press, with acronyms
like TDD (Test Driven Development), and several frameworks and tools to help out in testing.
</p>

<p>
Correctness monitoring and performance monitoring are similarly the activities that you need
to be concerned about. Sometimes engineers are reluctant to work on monitoring because it seems
to them that once the code is written and tested well, it will obviously work. Little do they
know that testing often misses cases that happen in real life. Unanticipated user inputs
(you coded up only for ascii characters and user inputs a chinese character), network failures,
disk getting full, swapping in systems some of the problems that may unexpectedly crop up
in production systems.
</p>

<h3>Heartbeat pings</h3>
<p>
Probably the simplest thing to track is if your machine is alive and reachable. There are plenty
of conditions under which your machine may become unreachable. The disk of your system may have
got full, or your program may have allocated too much memory resulting in thrashing, or your
cloud service provider may be experiencing network problems. Whatever the reason, end result
is going to be that your business will get impacted.
</p>

<p>
There are plenty of ways to track if the machine is reachable. The most popular way is that the
machine periodically sends a "heartbeat ping" to a central server. If the central several does
not receive a heartbeat ping for a threshold amount of time, it raises an alaram (by sending
a mail or sms or phone call to relevant people).
</p>

<p>
I have used Sensu, along with its accompanying UI Uchiwa for this purpose, and it has served
us satisfactorily. There have been countless occassions when machines have gone down and we
have detected that very soon and taken action. There are other products in this area. Of them,
nagios is perhaps the oldest and most versatile, but also harder to set up. The important thing
is to pick one solution and start using it.
</p>

<h3>Machine Metrics</h3>
<p>
A very generic set of metrics to track are machine metrics. This include metrics like CPU, memory
and disk utilization.
</p>

<p>
If you use a cloud based service provider like Amazon AWS or Google Compute Engine, your service provider
would provide you a bunch of these metrics, like CPU utilization or network bandwidth utilization. It is 
a good idea to put an alarm on some of these metrics, which can help you understand when your systems
are reaching their limits.
</p>

<p>
There is another use of tracking metrics: if you do an improvement in your software which is expected
to improve some machine metric: you can easily measure the effectiveness of your improvement. For instance,
to reduce infrastructure cost, we changed the backend from Python Django to Java Jetty. Since Python
is faster than Java (in computational workloads), we noted an immediate drop in CPU utilization as depicted
in following figure. (Note that we did not start with Java to begin with: starting off with Django
allowed us to develop our backend quickly. Only when the business succeeded to some extent and
infrastrcuture cost grew did we invest in writing backend in Java. There are other parts of the system
which continue to be in Python Django.)

<figure>
<img src = "cpu-utilization.png" height="300"/>
<figcaption>CPU utilization dropped when we switched from Python Django to Java Jetty</>
</figure>
</p>

<p>
There are some other machine metrics which are impossible or hard to be tracked by your cloud provider.
Memory utilization is one such metric. If you are like me, you run several disparate programs on one 
machine, each with its own memory needs, which typically rise as your business grows. Thus, it is
important to track the cumulative and individual memory utilization of those programs. Linux (and I
presume, other operating systems) provides utilities using which you can find resident set sizes
(the size of the memory used for a particular program). You should track resident set sizes of
your programs over time, and get concerned when it rises.
</p>

<p>
The approach which I have found helpful is to run a program periodically, compute the memory utilization
(as a fraction of total machine memory) for some predefined programs, and log top 10 of them to
a database. I use elasticsearch as the database to log such information, but equally effective would
be to log this to cloudwatch. Then you can plot the utilization over time, and set alarams if the 
cumulative memory utilization exceeds a threshold. If it does, it is perhaps time to move to a larger
machine, or better, to optimize your programs so that they consume lesser memory.
</p>

<p>
I have found using sensu plugins for tracking disk utilization periodically very helpful, but I imagine
any other mature solution would also be fine.
</p>

<p>
Similarly, disk utilization is another basic metric that you should track. For this too, I have found
sensu to be very helpful.
</p>

<p>
Infact, sensu is very configurable. You can track any metric periodically, and sensu will send you
a message if that metric goes above or below a threshold.
</p>

<p>
Another class of metric which you can track using your cloud provider relates to the number of requests
your online servers are getting and how well they are responding to those servers. This can be done
if you use your cloud provider's load balancers, for example AWS ELB (Elastic Load Balancer). I use this
to track how many requests my servers are receiving per unit. As of time of writing, my graph for
last 24 hours looks like this:

<figure>
<img src = "elb-request-rate-24-hours.png" height="300"/>
<figcaption>Request rate on my servers for past 24 hours</>
</figure>

These requests are send from mobile apps to QGraph's servers. You expect more requests when users
are active.  The times are in GMT. As you can see, the peak request rate is from 2 PM GMT to 4 PM GMT. These times
correspond to 7:30 PM to 9:30 India time, and 9 PM to 12 midnight Singapore time, two of the prominent
geogrpahies in which our software is used. It makes sense that during India/Singapore evening time,
the number of requests is the largest. On the other side, request rate hits the bottom at around 11 PM
GMT which is aroudn 4:30 in India and the country is in deep sleep. Periodic spikes are spurts in
user activity when one of our clients sends notifications to their users.
</p>

<p>
Following is the request rate on a daily basis: it has been quite consistent over past 2 week, but
rose around 13 days ago. It was probably related to a new client using product, or else an abnormally
high activity from one of our existing clients. Perhaps one of them blasted off too many notifications
to their users.
<figure>
<img src = "elb-request-rate-1-day.png" height="300"/>
<figcaption>Request rate on a daily basis</>
</figure>
</p>

<p>
Similarly you should track the average response times of your servers, like so:
<figure>
<img src = "elb-latency.png" height="300"/>
<figcaption>Latency during last 24 hours</>
</figure>
The latency is lower when the request rate is lower. Important thing is that the latency varies from
10ms to 35ms. So, we should put an alaram if latency grows higher than 50ms (Is the request rate too
high for servers to handle?) or lower than 5ms (Is a bug in the code causing the response to be returned
without processing fully?)
</p>

<p>
Similarly you can track the number of 5xx responses your server is throwing, and keep an alarm on
this metric exceeding a certain threshold.
</p

<p>
A related question is: how do you decide the threshold: keep it too aggressive and you will get so
many mails that everyone will start ignoring the alarams. Keep it too lenient, and you may miss
the bad event. My suggestion is that you should start somewhere in the middle towards the aggressive
side and adjust the threshold so that the volume of incorrect mails is tolerable.
</p>

<h3>Tracking Application correctness</h3>
<p>
Your application should also output summary data indicating its correctnes and performance. Some of this
data is the in form of metric, which you can track by putting it in elasticsearch or cloudwatch. For example,
our device backend puts the data in a Kafka queue from where a fleet of consumers picks up and processes
the data. It is important for us to be sure if all the data is actually being processed. To ensure this,
every 5 minutes, each consumer outputs the number of records it processes, and outputs to a file. The file
is tailed by td-agent, which puts the record in elastic search. On top of elastic search, we use kibana
to find the aggreate number of requests we process per 5 minutes. Here is that record, broken by 
the appids (app ids are identifiers for clients). Thus, this chart also tells us which clients are
sending us most data.
<figure>
<img src = "kibana-event-counter.png" height="400"/>
<figcaption>Number of requests consumed by consumers in last 24 hours, split by app ids</>
</figure>
</p>

<p>
We have at QGraph, a component which puts messages in SQS queue (SQS is a queuing serivce provided
by Amazon) and and a component which consumers these messages from the queue. The producer writes
to ElasticSearch the number of messages it is producing to the queue, while the consumer
writes to ElasticSearch the number of message it is consuming. In a healthy system, the metrics
better match, like this (ignore slight variations between production vs consumption figures):

<figure>
<img src = "crunner-vs-message-sender-1.png" height="400"/>
<figcaption>Number of requests produced vs number of requests consumed</>
</figure>
</p>

<p>
But when one of the systems is not behaving correctly, there will be mismatch in the figures.
Perhaps the consumer has gone down, and the production figure is smaller than consumption figure.
Or perhaps the consumer is consuming the same message repeatedly, leading to consumption figure
being larger than the production figure.
</p>

<p>
It is not always possible to have a few metrics corresponding to your systems which you can plot.
Sometimes, I make a table for a component. At QGraph, we run what we call "campaigns". A 
campaign is the set of notifications sent to a set of users. A campaign could be customized 
or uncustomized, it will be sent to a certain number of users, it takes some time to run, and
consumers some memory.  In our systems, typically a few hundreds of campaigns run every day.  
I like to track what are various metrics for each campaign that goes through our system, and thus
I make a table as following:
<figure>
<img src = "crunner-dashboard.png" height="300"/>
<figcaption>For monitoring some metrics, you need a table</>
</figure>
</p>

<h4>A picture is worth a thousand words</h4>

<p>
Often, a visual or pictoral representation is far more comprehensible than textual or numeric data.
</p>

<p>
At QGraph, we send customised notifications to users of ecommerce apps. We customise the message, 
the image, the deep link and the payload. The customisation happens in a myriad number of ways: 
we may customise on the basis of the what products the user has viewed in the past, what products
we recommend for him, and what products are trending in the market. If we fail to generate a customised
message, we fall back to sending a default message to the user.
</p>

<p>
It is important to check how customisation is happening. Sometimes, due to a bug, all notifications
may be falling back to the default message. One may try to numerically represent what fraction of
notifications are customised in what ways, but I found it useful to just generate a webpage that
visually shows what notifications are going to various users. A quick glance through this page
is good enough to check if everything is going fine.
<figure>
<img src = "notification-viewer.png" height="400"/>
<figcaption>A pictoral representation of notifications, along with the actual jsons.</>
</figure>
</p>

<h3>Other monitoring tools</h3>
<p>
There are some other tools which I have used, or else I think should be helpful:
</p>
<h4>Pingdom</h4>
<p>
Pingdom can ping various URLs that you provide to it, and mail you if some of the URLs are inaccessible.
Apart from this, it can also track the load time of web pages, and provide how long it takes to download
various JS files, CSS files, images etc. and theri sizes.It also provides suggestions about how you can decrease your
page load time. Further, you can find page load times from various locations across the world.
</p>

<p>
Using pingdom as a guide, we were able to cut the page load time by two third. A numerical page load time,
updated automatically, is a wonderful tool to keep yourself motivated to make constant progress.
</p>
<h4>Cronitor</h4>
<p>
As the functionality and the usage of your product expands, you will invariably have many cron jobs.
It becomes hard to monitor whether or not those crons are running properly, and finishing in time.
I have found the service called "Cronitor" useful in this regard. Once you integrate with cronitor
(which is very easy), it will send you a mail if crons don't run on time or take more than usual time.
</p>

<h3>Monitoring performance</h3>
<p>
Another important monitoring is performance monitoring, which is a topic in itself. We will consider
this topic in a separate chapter.
</p>

<h3>Logging</h3>
<p>
However hard you may try, you can simply assume that most likely you will be deploying a buggy software.
Particularly in a start up, where product or the feature itself is not fully validated, the focus is
on the speedy delivery of a software with manageable errors rather than striving for a high quality
software in the first version.
</p>

<p>
Given this reality, while writing software, it is important to write information to logs
so that when there is a report of software misbehavior one is able to speedily detect the 
the bug fast.
</p>

<p>
Most languages provide logging modules (like log4j in Java), which can be used to log information.
These modules usually provide various logging levels, like critical, debug, production etc. I like
to turn on the log level to high levels, unless there is a provable performance impact (See
"premature optimisation is the root of all evil".
</p>

<p>
In some case, I like to create log files with one directory per day (in the format YYYY-MM-DD),
and several files inside these directories, with one file per unit of work. This way, it is
easy to zoom in on a specific file when there is a report of malfunction.
</p>

<h3>Internal Dashboard</h3>
<p>
While logging gives you a history of what happened, you also need a dashboard to tell you
what is happening <i>right now</i>. How many users are logged in currently? What the the
database queries in progress right now? What is the table size of various database tables
currently? What all campaigns are running currently, and for how long they have been running?
</p>

<p>
Usually, this dashboard is wrapper across various small scripts running an various systems,
or database functionalities. One could always log in to the relevant system, and run the query.
However, the presence of a dashboard makes it a one click affair to get information and that
leads to more frequent consumption and observation of metrics, leading to a better understanding
of systems.
</p>

<p>
You can also use this dashboard to take actions in your system: modifying or deleting a user,
modifying or deleting an order, overriding some settings and so on. My dashboard consists 
of lots of links which take me to other dashboards of kibana or various tools that we use,
and various buttons that provide specific information. This is what it looks like:

<figure>
<img src = "internal-dashboard.png" height="500"/>
<figcaption>Internal Dashboard</>
</figure>

Admittedly, the UI is not great, but in internal tools, it is functionality and usability
that counts.

</p>
<p>
TALK ABOUT PROCESS ERROR LOGS
</p>
</body>
</html>
