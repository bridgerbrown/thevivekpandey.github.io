<html>
<head>
  <title> How to avoid drowning</title>
  <link rel="stylesheet" type="text/css" href="../style.css"/>
</head>
<body>
<h2>How to avoid drowning</h2>
<p>
At IIT Kanpur, I had a friend, called Abhishek Tiwari. We used to call him "Darjan", because his 
IIT JEE rank was 12. Abhishek once asked a bunch of us a question: "If you are drowning, what is 
the prerequisite for you to be saved?". Some answered that you should know swimming, others answered 
that some of your friends should know swimming. Some replied that you should shout. The correct 
answer was: "You should be aware that you are drowning."
</p>

<p>
That is true of computer systems, as it is true for humans. You canâ€™t resolve the problems in systems, 
unless you are aware of the problems. And for you to be aware of the problems, you need to monitor 
what is happening.
</p>

<p>
You may have a great mind, but to survive, you need to see and hear and feel what is happening around
you. An average mind with great curiosity is better a great mind with a mild curiosity about what 
is happening around you.
</p>

<p>
I have found that too often, engineers are either too confident that their systems will obviously
work correctly for all times to come, or have an ostrich attitude: they just don't dare to 
find if their systems are working correctly, lest they accidentally open a can of worms.
</p>

<p>
There was once telephony company. They built software which would route calls made to a customer 
support number to one of several agents. The agent would have the calling customer's details available 
on their laptop as they talked to the customer. Once, because of some problem, for a particular
client, the software stopped working. No customers were getting routed to any agents.
</p>

<p>
The client company decided not to report this to the telephony company. They were testing how
soon will the problem be detected. Well, the problem was never detected, and the client company
terminated the contract after one month.
</p>

<p>
This is the normal state of affairs if one does not actively monitor one's systems.
</p>

<p>
There is no silver bullet for monitoring. The guiding principle is: any piece of software should
produce some easily comprehensible summary output to prove that it is working correctly. This summary
output would mostly be some numbers, which are easy to chart or detect anomalies in, but it could
also be in some other format: tables or pictures or flamegraphs, whatever is easier to comprehend.
</p>


<h3>Heartbeat pings</h3>
<p>
Probably the simplest thing to track is if your machine is alive and reachable. There are plenty
of conditions under which your machine may become unreachable. The disk of your system may have
got full, or your program may have allocated too much memory resulting in thrashing, or your
cloud service provider may be experiencing network problems. Whatever the reason, end result
is going to be that your business will get impacted.
</p>

<p>
There are plenty of ways to track if the machine is reachable. The most popular way is that the
machine periodically sends a "heartbeat ping" to a central server. If the central several does
not receive a heartbeat ping for a threshold amount of time, it raises an alaram (by sending
a mail or sms or phone call to relevant people).
</p>

<p>
I have used Sensu, along with its accompanying UI Uchiwa for this purpose, and it has served
us satisfactorily. There have been countless occassions when machines have gone down and we
have detected that very soon and taken action. There are other products in this area. Of them,
nagios is perhaps the oldest and most versatile, but also harder to set up. The important thing
is to pick one solution and start using it.
</p>

<h3>Machine Metrics</h3>
<p>
A very generic set of metrics to track are machine metrics. This include metrics like CPU, memory
and disk utilization.
</p>

<p>
If you use a cloud based service provider like Amazon AWS or Google Compute Engine, your service provider
would provide you a bunch of these metrics, like CPU utilization or network bandwidth utilization. It is 
a good idea to put an alarm on some of these metrics, which can help you understand when your systems
are reaching their limits.
</p>

<p>
There is another use of tracking metrics: if you do an improvement in your software which is expected
to improve some machine metric: you can easily measure the effectiveness of your improvement. For instance,
to reduce infrastructure cost, we changed the backend from Python Django to Java Jetty. Since Python
is faster than Java (in computational workloads), we noted an immediate drop in CPU utilization as depicted
in following figure. (Note that we did not start with Java to begin with: starting off with Django
allowed us to develop our backend quickly. Only when the business succeeded to some extent and
infrastrcuture cost grew did we invest in writing backend in Java. There are other parts of the system
which continue to be in Python Django.)

<figure>
<img src = "cpu-utilization.png" height="300"/>
<figcaption>CPU utilization dropped when we switched from Python Django to Java Jetty</>
</figure>
</p>

<p>
There are some other machine metrics which are impossible or hard to be tracked by your cloud provider.
Memory utilization is one such metric. If you are like me, you run several disparate programs on one 
machine, each with its own memory needs, which typically rise as your business grows. Thus, it is
important to track the cumulative and individual memory utilization of those programs. Linux (and I
presume, other operating systems) provides utilities using which you can find resident set sizes
(the size of the memory used for a particular program). You should track resident set sizes of
your programs over time, and get concerned when it rises.
</p>

<p>
The approach which I have found helpful is to run a program periodically, compute the memory utilization
(as a fraction of total machine memory) for some predefined programs, and log top 10 of them to
a database. I use elasticsearch as the database to log such information, but equally effective would
be to log this to cloudwatch. Then you can plot the utilization over time, and set alarams if the 
cumulative memory utilization exceeds a threshold. If it does, it is perhaps time to move to a larger
machine, or better, to optimize your programs so that they consume lesser memory.
</p>

<p>
I have found using sensu plugins for tracking disk utilization periodically very helpful, but I imagine
any other mature solution would also be fine.
</p>

<p>
Similarly, disk utilization is another basic metric that you should track. For this too, I have found
sensu to be very helpful.
</p>

<p>
Infact, sensu is very configurable. You can track any metric periodically, and sensu will send you
a message if that metric goes above or below a threshold.
</p>

<p>
Another class of metric which you can track using your cloud provider relates to the number of requests
your online servers are getting and how well they are responding to those servers. This can be done
if you use your cloud provider's load balancers, for example AWS ELB (Elastic Load Balancer). I use this
to track how many requests my servers are receiving per unit. As of time of writing, my graph for
last 24 hours looks like this:

<figure>
<img src = "elb-request-rate-24-hours.png" height="300"/>
<figcaption>Request rate on my servers for past 24 hours</>
</figure>

These requests are send from mobile apps to QGraph's servers. You expect more requests when users
are active.  The times are in GMT. As you can see, the peak request rate is from 2 PM GMT to 4 PM GMT. These times
correspond to 7:30 PM to 9:30 India time, and 9 PM to 12 midnight Singapore time, two of the prominent
geogrpahies in which our software is used. It makes sense that during India/Singapore evening time,
the number of requests is the largest. On the other side, request rate hits the bottom at around 11 PM
GMT which is aroudn 4:30 in India and the country is in deep sleep.
</p>

<p>
Following is the request rate on a daily basis: it has been quite consistent over past 2 week, but
rose around 13 days ago. It was probably related to a new client using product, or else an abnormally
high activity from one of our existing clients. Perhaps one of them blasted off too many notifications
to their users.
<figure>
<img src = "elb-request-rate-1-day.png" height="300"/>
<figcaption>Request rate on a daily basis</>
</figure>
</p>

<p>
Similarly you should track the average response times of your servers, like so:
<figure>
<img src = "elb-latency.png" height="300"/>
<figcaption>Latency during last 24 hours</>
</figure>
The latency is lower when the request rate is lower. Important thing is that the latency varies from
10ms to 35ms. So, we should put an alaram if latency grows higher than 50ms (Is the request rate too
high for servers to handle?) or lower than 5ms (Is a bug in the code causing the response to be returned
without processing fully?)
</p>

<p>
Similarly you can track the number of 5xx responses your server is throwing, and keep an alarm on
this metric exceeding a certain threshold.
</p>

<p>
A related question is: how do you decide the threshold: keep it too aggressive and you will get so
many mails that everyone will start ignoring the alarams. Keep it too lenient, and you may miss
the bad event. My suggestion is that you should start somewhere in the middle towards the aggressive
side and adjust the threshold so that the volume of incorrect mails is tolerable.
</p>

<h3>Tracking Application correctness</h3>
Your application should also output summary data indicating its correctnes and performance. Some of this
data is the in form of metric, which you can track by putting it in elasticsearch or cloudwatch. For instance,
</body>
</html>
