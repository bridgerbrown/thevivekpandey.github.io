<html>
<head>
  <title>On performance improvement</title>
  <link rel="stylesheet" type="text/css" href="../style.css"/>
</head>
<body>
<h2>On performance improvement</h2>

<p>
Everyone wants superior performance for their product or service. However, unless you are methodical
about it, it is easy to spend a lot of time optimizing your code and systems, with little actual
improvement to show for the efforts. This chapter discuss some of aspects to consider when trying
to improve the performance of the systems.
</p>
<h3>Do you need superior performance?</h3>
<p>
While having a good performance is, well, good, before you take up an optimization attempt, you should
take a step back and think if you need better performance. Any time put in improving performance is
time put in doing some other activity, and thus performnace improvement efforts need to justify
themsleves relative to other activities that could be done.
</p>

<p>
This sounds obvious, but many times, engineers are driven by their insticts of aesthetics and
problem solving, rather than pragmatism. The thrill of improving software may outweight the 
pragmatic consideration whether their improvemnt is required at all.
</p>

<p>
I was once walking and on the sidewalk and saw the pedestrian signal turn green at a distance.
I committed to myself that I am going to cross the road before the signal turned red. I 
started running, and just managed to cross the road before the signal turned red. Only after
this I realized that my destination was on the other side of the signal and I never needed
to cross the road. I waited for another green signal to cross the road back. Indeed, sometimes,
overcoming the challenges becomes more important than practical considerations.
</p>

<p>
Does it really matter if your nightly job takes 30 min instead of 1 hour? Does it matter
if you reduce the memory consumption of program from 100 GB to 90GB? Would your users
appreciate if the latency of requests goes down from 20ms to 19.8ms? In many situations,
the answer is no, and you should move on to the next problem, which hopefully, matters.
</p>

<h3>Amadahl's / Gustafson's laws</h3>
<p>
Another factor to keep in mind while working on performance improvement is Amadahl's law.
Amadahl's law, reworded as Gustafson's law
--footnote--
Amadah's law and Gustafson's law are very simple facts. These guys were lucky that they
coined their laws which became so famous.  Gene Amadahl was an exciting fellow, who kept 
on founding companies till his sixties, and led a remarkable life.

states that overall speedup of a program is dependent not only on the speed up by which
you increase the latency of some portion of the program, but also on the portion of the
program which you do not improve.
</p>

<p>
Consider an example. Suppose a program's execution time is 100s. Suppose its execution can be 
divided into two parts: A and B. Part A takes 20s and Part B takes 80s. Now, if you speed up
part A by 90%, such that Part A takes only 2s, overall the program will take 82s, and thus
there is a speed up of 12% in overall program execution time. However, if you speed up 
Part B by a more moderate 50%, Part B takes 40s, leading to an overall execution time of 60s,
implying a speedup of 40%.
</p>

<p>
While you may see green pastures of optimization opportunities in parts of your system, do not
jump to work on them unless the overall impact of those improvements justifies the efforts.
</p>

<p>
Say you are writing an HTTP server. Say it takes an average of 10ms for your server to respond to
the request. You have figure out a way to reduce it by 20%, so that it will take only 8ms. 
10ms vs 8ms sounds like a handsome improvement, and your end users will appreciate a faster
website, won't they?
</p>

<p>
Well, not so fast. You need to consider that from end user's persepective, there is network
latency too: San Francisco to New York network latency is like is ~50ms, cross continent
network latency is even higher. So, you are reducing user preceived latency from 60ms to 58ms,
which is not that impressive.
</p>

<p>
Note that if you are doing 10ms to 8ms change with code optimization, without introducing
extra hardware (e.g., for caching), you may still justify your attempts if there is significant
infrastructure cost reduction. You then need to check how much money you end up saving.
</p>

<p>
Perhaps, while reviewing the code you found that there is a linear search happening on an array,
and using hash map can make search O(1). But before you implement improvement, consider the
size of the array, and how many times that search is done. Will you be improving the 
performance sizeably?
</p>

<p>
Perhaps you found that a datbase table is being queried on a certain column and there is
no index on that column. Before you create the index, consider how much does that buy you.
Is the table size large enough for the index to matter at all?
</p>

<h3>Measurement driven optimization</h3>
<p>
"Premature optimization is the root of all evil" said Edgar Dijkstra. For him to come up with
the quote, he himself would have wasted some time in premature optimization, or else seen
others wasting their time. Indeed, premature optimization is an urge that is to be resisted
continually.
</p>

<p>
So, what is full term (as opposed to premature) optimization? It is an optimization driven by
measurement. You measure, make an educated guess about the efficacy of the improvement
that you are undertaking, do the improvement, and measure again. Then you repeat the process.
</p>

<p>
The measurement consists of two parts: the metric and the profile.
</p>

The metric is usually a single
number representing the performance of an entire sub system. It could be running time of a program. 
For an HTTP server, this could
be response time. For a build system, this would be time to build a fresh build. In a throughput
oriented system, it could be how many requests per second a server can support before
CPU utilization of the server exceeds 70%. For a chat server, it could be the number of
concurrent connections supported before the response times exceed, say 10ms. For a frontend app
it could be page load time. For a caching server, it could be the hit rate.
</p>

<p>
Sometimes, the metrics could be at high level: how many batch jobs are failing per day? How many
open bug reports are there?
</p>

<p>
You often need to aggregate individual numbers to come up with a single metrics. For example,
while calculating the overall latency of all the requests sent to an HTTP server over a day,
you may take the average of individual latencies. While calculating aggregate metrics, while
average sounds most natural, this may not always be the case: there are instances when
90%ile value may be better, or maximum may be better.
</p>

<p>
Note that they are metrics in our control, not like active users per day.
</p>
<h3>Choosing the right metrics</h3>
<h3>Performance can always be improved</h3>
<h3>What was luxury yesterday becomes a necessity today</h3>
</body>
</html>
