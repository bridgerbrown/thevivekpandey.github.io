<html>
<head>
  <title> Attitude Matters</title>
  <link rel="stylesheet" type="text/css" href="../style.css"/>
</head>
<body>
<h2>Attitude Matters</h2>
<p>
This chapter is a collection of miscellaneous attitude related problems and deficiencies that I
have encountered in various engineers.
</p>

<h3>Proximate and Ultimate causes</h3>
<p>
A framework which is to helpful in improving from the mistakes is to think in terms of proximate
and ultimate causes.
</p>

<p>
As discussed earlier, we had a Python function in our code
</p>
<pre>
def some_func(param1, respect_frequency=False):
   #some functionality. By default, frequency will not be respected.
</pre>

<p>
Now, one developer, while coding up a feature which required him to use some_func(), completely
forgot that he needed to make sure that frequency needs to be respected. He was so engrossed
with the intriciacies of the code that he was writing that the through of respecting the frequency
did not come to his mind. He simply called some_func() with one argument as one other module
was doing, and everything seemed to be working. It was only in production that we found out
that the frequency was not being respected.
</p>

<p>
Now, let us analyze why did the problem happen? The proximate cause is that the developer did
not pay full attention to the code that he was writing. He should have paid attention to
the default values of various arguments and seen if default values were suitable for him.
</p>

<p>
But the ultimate cause is that using default values in this situation was a bad practice.
Such a setting should not be hidden in defaults.
</p>

<p>
When we encounter the bugs, we should not only try to solve the proximate cause of the bug
(like using the correct value of the parameter in the above example), we should also solve
the ultimate cause of the bug (perhaps making the particular value required, rather than optional,
and taking a look whether you are using optional values at many places where you
should be using required values)
</p>

<p>
In other cases, the ultimate cause may lie outside tech. In one instance, I found that
a particular component was broken for a long time and we did not detect it.
</p>

<p>
The proximate cause of us not detecting the problem for a long time was that we had
not set up any monitoring or alarm on the component. However, the ultimate cause was that
no one owning the component. The developer who had written the component had left
the company, and the developer who took knowledge transfer from him never really internalized
the fact that the component was now his responsibility. The reliability of the component
increased when it was made explicit to the engineer that the component was his responsibility.
</p>

<h3>A framework for learning</h3>
<p>
STEM (Science, technology, engineering, mathematics) are different from the fields like religion or politics
in that there is, for the most part, an objective reality in STEM which the pursuers of STEM
like to strive towards. This is unlike religion, politics or to varying degree, other softer
disciplines where "correctness" is often determined by how many people believe in what you say,
and strongly they belive in some things.
</p>

<p>
(Bottom note)
Note that the notion of "objective reality" is debatable though. At the deepest level, Quantum Physics
tells us, there is no objective reality, it is all a cloud of probabilities.
</p>

<p>
Presence of an objective reality is very consoling for truth seekers. In various other fields you
need to convince people that you are right, and convincing is an art of pursuation, and your
position need not be backed by truth. Thus, populists rise to the highest echelons of power.
However, by no means is finding the objective truth easy.
</p>

<p>
Consider medicine. Till some years ago, they used to think that meat is very good for human health,
but slowly vegetarianism and even veganism is gaining ground. They used to bad mounth egg yolk,
but now they say it is okay to eat it.
</p>

<p>
In Physics, they thought that classical mechanics was as all that there was to discover, 
and then it was a matter of calculation to calculate the state of the world at any given time.
But then we discovered quantum mechanics and found that the reality is much more complicated.
</p>

<p>
Despite the hits and misses of the science, seems to be continually making improvement. The sum
total of our knowledge keeps on increasing and as time passes, we understand the world around
us in a better way.
</p>

<h4>Mental Models</h4>
<p>
As in science, so in systems development. Computer systems, starting from microprocessor and
instruction set architecture, all the way up to opearating systems and compilers and network
protocols, are incredibly complicated. It is not possible for you to have more than a superficial
knowledge of most of the stack. What you should have a is a very simple mental model about
what the things that you work with. When required, you should refine your mental model with
finer details. At times, new facts will emerge which will be in conflict with the mental
model that you have. In those situations, you revise your mental model.
</p>

<p>
Any new software or technology that you come across should augment your mental model. It should
find a place in your existing mental model. That way you will be able to understand new
technology in a proper context.
<p>

<p>
For instance, you can have a mental of model of a computer as a machine which
executes instructions. Each instruction is about doing some arithmetic on numbers. We
have discarded all I/O in above mental model, but it suffices as a basic model.
</p>

<p>
In your mental model, you should be able to "explain" why the things are the way they are.
For instance, disk access is slower than memory access because memory is located closer
to the processor. C is faster than Python because being dynamically typed, the interepretor
needs to infer the type before executing every instruction, which slows it down.
</p>

<p>
Mental models can help you like they helped me in the following case.
There was a time when I was not familiar with columnar dateabases. 
We used to store our data in MySQL.
We started facing scaling challenges with our OLAP workloads and we discovered
columnar databases, in particular, Vertica. On a simple proof of concept, we
found vertica to be blazingly faster compared to MySQL. So, now I needed to
form a mental model about why Vertica is way faster than MySQL.
</p>

<p>
On reading a few papers, I found that Columnar databases
store data column wise, rather than row wise, which is what is done in usual, row
oriented databases like MySQL. Thus, for the queries which access only a few columns,
we avoid reading other columns, leading to better performance. Further, values in
columns are similar to each other (all are strings, or all are integers), and
can be efficiently compressed, leading to further performance gains.
</p>

<p>
Given this mental model, I was able to design the DB schema, specificy compression
algo for various columns (like, run length encoding would be very suitable
for the columns in which value stored is usually 0), and achieve great performance
gains.
</p>

<p>
Once Amazon sales people came to our office and tried to sell us redshift. Redshift
too is a columnar database. They claimed that redshift would be 5x faster than vertica.
I asked them why that is so. I was ready to accept their claim, but their claim had
to fit in my mental model. They just kept saying the redshift is faster. I researched
about redshift, but could not find a fundamental difference. Vertica was a well known
name in columnar databases, so it was hard to believe that some other company can
outperform vertica so drastically.
</p>

<p>
Anyway, since Amazon sales people were insistent, they were able to make use do a
proof of concept study on our real workloads. We found redshift's performance to
be around 50% of that of vertica. Redshift people asked us for a slice of our
workload so that they can do the study themselves. We complied and they never
returned back.
</p>

<p>
What saved me was the mental model. I tried to fit and redshift in my mental model,
and when I could not, I had to discard it.
</p>

<p>
There have been other scenarios where the mental model has failed me. I could not
fit something, discarded it, only to find later that there was a way to neatly fit
the new phenomena in the mental model. That is fine. You continually revise
your mental models in light of all the facts that you know. 
</p>

<h3>A framework for solving problems</h3>
<p>
As programmars, we write a lot of code. With time, the code base grows and various systems that we have
written interact with each other in ways which overwhelm our abilities to comprehend.
</p>

<p>
When things don't work as planned, or there are unexpected problems, we need to do detective work
to find out the source of the problem. Many a times, even otherwise good engineers have a hard
time doing this.
</p>

<p>
Humans are ingrained with certain biases, which hinder accurate redressal of problems. Here are 
a few of them:
</p>

<p>
Firstly, there is <u>Jumping to the conclusion fallacy</u>. We sometimes form unsubstantiated
opinions about why things are the way they are, and start blaming incorrect things.
</p>
<p>
At VMware, I worked with two teams: Virtual Machine Monitor (VMM) team and Virtual Machine
Kernel (VMKernel) team. When new type of virtualization technology, called NPT (Short
for nested page tables) was introduced, VMM team needed what is called "large pages" 
to maintain enhanced levels of performance. It was the duty of VMKernel team to provide
large pages. It was not very easy for VMKernel team to provide large pages: they
put only a small effort in providing large pages.
</p>

<p>
When performance measurements were made, workloads were running signficantly slower than
earlier, and we could see stats that number of large pages being used was small.
</p>

<p>
VMM put team put pressure on VMKernel team to provide more large pages, and VMkernel team
reluctantly worked to improve the availability of large pages, but they could not increase
it by much. The algorithm to drastically available the availability was complex and they
were shying away from it. In private they complained that the number of large pages they
were providing ought to be enough. Performance of workloads being deteroritated, there
was perssure on VMM team to improve it, and there were noises that they be given control
of VMKernel code if VMkernel engineers are reluctant to make desired changes.
</p>

<p>
The two teams were nearly siloed, and had limited communications (partly the location was
to blame: the two teams sat in different offices). I was a sort of intermediary and could
appreciate the concerns of both teams: VMM team needed more large pages to increase performance,
and VMkernel team argued that if its minor efforts were not yield measurable benefits, how
are we sure that major efforts will. I did an investigation and found a startling fact:
VMM was unable to use the large pages it was being provided. For reasons that had escaped
our attention till now, VMM was "breaking" the large pages that were being provided to it.
On this news, VMkernel team sighed with relief, and VMM team became busy with strategies
to avoid breaking the pages.
</p>

<p>
Why did all this happen? The reason is that everybody, including VMkernel team, jumped
to the conclusion that deterioration in performance is because of unavailability of pages.
In midst of all the heat and several tasks to be done, it is tempting to take such shortcuts.
What we should have done is, to get an estimate of how many large pages are required for
a good performance, and then check if VMkernel is giving those many large pages. That would
have avoided a catch-all excuse to blame VMkernel for any performance problems.
</p>

<p>
The lesson is that we our initial guess is only a hypothesis, which needs to be validated.
You cannot conjure up something and start believing in it. There should be some validation
that your hypothesis is indeed correct. Confusing hypothesis with validated statement
should be avoided.
</p>

<h3>Hypothesis, assumption, validation and conclusion</h3>
<p>
When you solving problems such as the one outlined in the previous section, you need to
scrutinize each of your statements, as to wheter it is:
</p>

<ol>
<li>
<p>
A hypothesis: which is something which you think can be true, or strongly believe to be true,
but has not been supported by other facts. While solving a problem, there could be multiple
competing hypotheses.
</p>
</li>

<li>
<p>
An assumption is something which you take for true with investigating, often even without
thinking that it could be false as well. Sometimes, while solving a problem, you are unable
to come up with any hypothesis to explain the phenomenon, or else non of your hypotheses
are able to stand the test of validation, you should start questioning your assumptions.
</p>

<p>
Suppose someone reports a bug in your system, and you are unable to find the cause of the bug,
you should start questioning various assumptions: (a) Is the reporter mistaken? Can he
reproduce the bug? (b) Is the reporter using the software in a correct way? There are many
cases, where this assumption breaks down: the problem is really a problem of understanding
and not a problem of software.
</p>
</li>

<li>
<p>
When a hypothesis is supported by some facts, it becomes "validated". Then it becomes a
conclusion, or a validated fact.
</p>

</p>
</li>
</ol>

<p>
Epistomologically, there are various problems with above thinking: how can be sure that a hypothesis
has been validated, how can you enlist all your assumptions, and so on. But we are not philosophisizing
an air tight way to acquire knowledge, we only want to solve the problems at hand in an
efficient way.
<p>
Firstly, there is is <u>Post hoc fallacy</u>:
Since event Y happened after event X, event Y must have been caused by event X. The problem is
just before Y, there are so many events that happened. You will usually have an incomplete
picture of what all happened before Y. Thus, you would be biased towards those activities which
you did.
</p>

<p>
You have to start somewhere, so it is okay to have the hypothesis that "X has caused Y". However,
before you start taking actions, you need to validate your hypothesis.
</p>
</body>
</html>
